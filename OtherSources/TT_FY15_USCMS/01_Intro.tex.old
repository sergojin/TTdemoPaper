\section{Introduction}

\noindent The physics reach of the HL-LHC experiments will depend critically on the ability of their trigger systems to discriminate between interesting rare events and background. For example, the CMS muon trigger will reach an unacceptably large trigger rate at high luminosity due to the number of hits in the muon detectors.  The trigger rate can be reduced to an acceptable level if tracks can be found in the inner detector and matched to the muon candidates. In order to be viable at Level 1, such a trigger decision would need to have a latency of the order of a few microseconds or less and therefore, despite the progress in computing technology expected for the next few years, given the complexity of the problem and the extremely crowded event structure, will need to be implemented mostly using specialized hardware.

\noindent Hardware-based pattern recognition for fast silicon-based triggering on charged tracks was first developed for the CDF Silicon Vertex Trigger (SVT) at the Fermilab Tevatron in the 1990's.  The method used there~\cite{bib:Rist-89} was based on a massively parallel architecture - the Associative Memory - to identify patterns efficiently at high speed, and has provided an effective solution to fast track triggers in a hadron collider environment. The Associative Memory approach was successfully used in CDF at trigger Level 2 and the same approach is now being implemented for Atlas (FTK), also at Level 2, albeit with a much improved hardware architecture implemented with modern technology.  Since the Associative Memory approach is so far the only proven approach to tracking trigger in a hadron collider environment, it is chosen here as the baseline for our R\&D program for CMS. However, the design of an Associative Memory system capable of dealing with the much higher complexity of the HL-LHC collisions, within the much shorter latency required by Level 1 triggering, poses significant technical challenges. An aggressive R\&D program is currently ongoing to demonstrate its feasibility and to explore other approaches to the pattern recognition problem.

\noindent Track reconstruction typically consists of two steps: pattern recognition followed by track fitting. Pattern recognition involves choosing, among all the hits present in the detector, those hits that were potentially caused by the same particle. This stage produces a set of ”hits of interest”. Track fitting involves extracting track parameters from the coordinates of the ”hits of interest”. When time constraints are not so stringent, track reconstruction is implemented in software, often using processors running in the upper levels of a data acquisition system. However, software algorithms running on standard CPU’s are typically not fast enough for these extreme applications. As will be described below, in the traditional Associative Memory approach, the pattern recognition stage is performed by Associative Memories, while track fitting is done using a simplified least squares fitting algorithm using a linear expansion of the analytical expression of the track trajectories around the hit locations in the detector, running on FPGAs. In what follows we will assume this approach as our baseline but we will make sure that the architecture we are proposing lend itself to testing and comparing other possible solutions.

\subsection{The Challenges for tracking trigger at L1}

\noindent Current estimates show that only a few microseconds will be available for track finding and fitting at Level 1. Two difficult challenges one has to face are data dispatching and pattern recognition. Data dispatching is where the stubs from many thousands silicon modules must be organized and delivered to the appropriate eta-phi trigger towers. Due to the finite size of the beam’s luminous region in z and the finite curvature of charged particles in the magnetic field, some stubs must be duplicated and sent to multiple towers in an intelligent way. This is especially challenging for Level 1 track trigger. Since all this must be done within a very short time (of the order of a micro-second), communication between processing elements in different towers requires very high bandwidth and very low latency. 

\noindent To get a feeling of the complexity of the pattern recognition task, we can use the Atlas FastTracK (FTK)~\cite{bib:FTK-10} project as an example. Since the design requirements of the FTK system are now known from extensive simulations, numbers from FTK, in some case, can be used as an order of magnitude estimate for CMS. The original CDF SVT system, in operation from 2001 to 2005, had a total of 384,000 Associative Memory patterns, while the ATLAS FTK system for the Level 2 trigger effectively requires about 1 billion patterns in order to handle a luminosity of $3\times10^{34}~cm^{-2}s^{-1}$~\cite{bib:FTK-10}. This is three orders of magnitude more Associative Memory patterns than the SVT. The Level 1 Track Trigger upgrade for CMS has the advantage of having the $p_T$ stub finding  done upstream, therefore it may not require as many patterns as FTK. However, the pattern recognition engine has to run at much higher speed to be usable at Level 1. It should be noted that larger available pattern density in the hardware is beneficial as it reduces some difficulties associated with track fitting, thus leading to lower overall latency. 

\noindent In addition to the challenges above, extremely fast and effective track fitting is also required. Extensive R\&D and experimentation of innovative ideas is needed in this area.

\subsection{On going R\&D activities at CMS}

\noindent The architecture we have recently proposed for the CMS L1 tracking trigger system is based on ATCA with full-mesh backplane. The large inter-board communication bandwidth provided by the full-mesh backplane is used to time multiplex the high volume of incoming data in such a way that the I/O bandwidth demands are manageable at the board and chip level, making it possible for an early technical demonstration with existing technology. The resulting architecture is scalable, flexible and open. For example, it allows different pattern recognition architectures and algorithms to be explored and compared within the same platform. Also, given that AMC specifications are designed to work with both ATCA and MicroTCA, this architecture allows a natural long term integration of TK-DAQ (AMC card based) and TK-TRIG (ATCA based).

\noindent The proposed architecture and system demonstration concept has been well received within the tracker Phase 2 upgrade community and work is in progress to better define the concept.  At the same time, establishing international collaborations within CMS to work on this project is essential. One of the main activities in the coming year (FY14) will consist of extensive simulation efforts, by physicists, to establish technical specifications based on Phase 2 physics goals. At the same time, students and postdocs from all groups will be offered a unique opportunity to develop hardware experience by getting involved with the design, construction and commissioning of the vertical slice demonstration over the next few years. Some of the groups, for the longer term, are also interested in getting involved with the development of the algorithms for the post-track-finding stages and of the interfaces with the global trigger. 

\noindent This document presents a proposed architecture to demonstrate the track reconstruction at L1 for CMS.  As already mentioned above, the proposed demonstrator is by no means the final system and serves the purpose of demonstrating feasibility and identifying bottlenecks of the L1 tracking trigger. This will be a living document and is intended to define the tracking trigger project and organize the efforts towards the Technical Proposal, the Vertical Slice Demonstration System, and the Tracker Technical Design Report (TDR). It will be written in such a way to make it easy not only for new groups to learn, but also to communicate with all the relevant tracker, trigger and physics groups.

\clearpage
